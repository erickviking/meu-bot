// File: src/services/transcription.service.js (Vers칚o Corrigida e Robusta)
const { OpenAI } = require('openai');
const config = require('../config');

const openai = new OpenAI({ apiKey: config.openai.apiKey });

/**
 * Transcreve um 치udio usando OpenAI Whisper (whisper-1).
 * Aceita um Buffer (ex.: 치udio baixado do WhatsApp em OGG/OPUS).
 *
 * @param {Buffer} buffer - Arquivo de 치udio em buffer
 * @returns {Promise<string>} - Texto transcrito
 */
async function transcribeAudio(buffer) {
    try {
        if (!buffer || !Buffer.isBuffer(buffer)) {
            console.error('[TranscriptionService] Buffer inv치lido ou vazio.');
            return '';
        }

        // --- IN칈CIO DA CORRE칂츾O ---
        // Precisamos enviar o Buffer como um File/Blob para que o SDK interprete corretamente.
        // O OpenAI SDK aceita `{ file: Buffer, filename: 'nome.extens칚o' }`.
        const audioFile = {
            file: buffer,
            filename: 'audio.ogg', // Nome obrigat칩rio para o parse correto
        };

        console.log(`[TranscriptionService] Iniciando transcri칞칚o... Tamanho do buffer: ${buffer.length} bytes`);

        const transcription = await openai.audio.transcriptions.create({
            file: audioFile, // 游댳 Agora passamos o objeto com filename
            model: 'whisper-1',
            // language: 'pt', // 游댳 Opcional: for칞a a transcri칞칚o em portugu칡s
        });
        // --- FIM DA CORRE칂츾O ---

        const result = transcription?.text?.trim() || '';
        console.log(`[TranscriptionService] Transcri칞칚o conclu칤da: "${result}"`);
        return result;
    } catch (error) {
        // Log detalhado para debugar respostas da API
        console.error('[TranscriptionService] Erro ao transcrever 치udio:', error.response?.data || error.message);
        return '';
    }
}

module.exports = { transcribeAudio };
